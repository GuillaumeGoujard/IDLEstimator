%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{IDL\_Guide Documentation}
\date{Dec 10, 2019}
\release{0.9}
\author{us}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


This package can be used to fit an Implicit Deep Learning (IDL)
model for regression and classification purpose.


\chapter{Introduction}
\label{\detokenize{sections/introduction:introduction}}\label{\detokenize{sections/introduction::doc}}
This package can be used to fit an Implicit Deep Learning (IDL) model for regression
and classification purpose.

The IDL.fit function estimates a vector of parameters by applying successively
gradient descents (see more at {\hyperref[\detokenize{sections/gradient_descents:gradient-descents}]{\sphinxcrossref{\DUrole{std,std-ref}{Gradient Descents}}}}) and dual ascent
(see more at {\hyperref[\detokenize{sections/dual_ascents:dual-ascents}]{\sphinxcrossref{\DUrole{std,std-ref}{Dual Ascents}}}}).


\section{Implicit Deep Learning}
\label{\detokenize{sections/introduction:id1}}
Given an input \(u \in \mathbb{R}^n\), where n denotes the number of features,
we define the implicit deep learning prediction rule \(\hat{y}(u) \in \mathbb{R}^n\) with ReLU activation
\begin{equation}\label{equation:sections/introduction:eq_1}
\begin{split}\begin{align}
    \hat{y}(u) &= Ax + Bu + c \\
    x &= (Dx + Eu + f)_+,
\end{align}\end{split}
\end{equation}
where \((.)_+ := \text{max}(0,.)\) is ReLU activation, \(x \in \mathbb{R}^h\) is called the hidden variable
(h is the number of hidden features), \(\Theta := (A,B,c,D,E,f)\) are matrices and vectors of appropriate size, they define the
parameters of the model. The hidden variable \(x\) is implicit in the sense that there is in general no analytical
formula for it, this is different from classic deep learning for which, given the model parameters, the hidden
variables can be computed explicitly via propagation through the network.


\section{Notation and definitions}
\label{\detokenize{sections/introduction:notation-and-definitions}}
We denote \(\Vert . \Vert\) the eucledian norm, \(\Vert . \Vert_2\) the corresponding norm (i.e. the spectral norm) and
\(\Vert . \Vert_F\) the Frobenius norm. \(\mathbb{R}_+^n\) denotes the positive orthant of the vector space \(\mathbb{R}^n, \mathbb{S}^n\)
the set of real symmetric matrices of size \(n\) and \(\mathbb{S}_+^n\) the cone of positive semi-definite matrices of size \(n\). The transpose of a matrix or
vector is denoted \(.^T\) and elementwise product is denoted \(\odot\). Given a differentiable function \(f\) from \(\mathbb{R}^{n \times p}\) to \(\mathbb{R}\)
we define the scalar by matrix partial derivative in denominator layout convention as
\begin{equation*}
\begin{split}\frac{\partial f}{\partial A} = \nabla_A f = \begin{bmatrix}
        \frac{\partial f}{\partial A_{1,1}} & \cdots & \frac{\partial f}{\partial A_{1,p}} \\
        \vdots & \ddots & \vdots \\
        \frac{\partial f}{\partial A_{n,1}} & \cdots & \frac{\partial f}{\partial A_{n,p}}
    \end{bmatrix}
    \in \mathbb{R}^{n \times p}.\end{split}
\end{equation*}
We say that a function \((x,y) \rightarrow f(x,y)\) with seperable domain of definition \(\mathcal{X} \times \mathcal{Y}\) is bi-convex in \((x,y)\),
if for all \(x \in \mathcal{X}\), the function \(y \rightarrow f(x,y)\) is convex and for all \(y \in \mathcal{Y}\) the function \(x \rightarrow f(x,y)\) is convex.
We say that a function is smooth if it is differentiable and its gradient is Lipschitz continious. We say that \(f\) is bi-smooth if it is smooth in \(x\) given \(y\) and
vice-versa. An example of bi-smooth and bi-convex function is \((x,A) \rightarrow x^TAx, A \in \mathbb{S}_+^n\).


\section{Well-posedness}
\label{\detokenize{sections/introduction:well-posedness}}
We say that matrix \(D\) is well-posed for \eqref{equation:sections/introduction:eq_1} if there exists a unique solution \(x = (Dx + \delta)_+ \forall \delta \in \mathbb{R}^h\).
Using the fact that ReLU is 1-Lipschitz we have for \(x_1,x_2 \in \mathbb{R}^h\)
\begin{equation*}
\begin{split}\Vert (Dx_1 + \delta)_+ - (Dx_2 + \delta)_+ \Vert \leq \Vert D(x_1 -x_2) \Vert \leq \Vert D \Vert_2 \Vert x_1 -x_2 \Vert.\end{split}
\end{equation*}
If \(\Vert D \Vert_2 < 1\) we have that the map \(x \rightarrow (Dx + \delta)_+\) is a strict contraction. In that case, Banach’s contraction
mapping theorem applies, showing that the equation \(x = (Dx + \delta)_+\) has a unique solution. In that case, a solution \(x\) can be computed via the
Picard iterations
\begin{equation*}
\begin{split}x^{k+1} = (Dx + \delta), k = 1,2, \cdots.\end{split}
\end{equation*}
Note that \(\Vert D \Vert_2 < 1\) is only a sufficient condition for well-posedness. Nevertheless this is the only condition
we will consider in this article.


\section{Loss Functions}
\label{\detokenize{sections/introduction:loss-functions}}
** section 3.2 equation 4 ** + Classification loss
(see more at {\hyperref[\detokenize{sections/learning:learning}]{\sphinxcrossref{\DUrole{std,std-ref}{Learning Process}}}})


\section{Description of the learning process}
\label{\detokenize{sections/introduction:description-of-the-learning-process}}
(see more at {\hyperref[\detokenize{sections/bi_convex_formulation:formulation}]{\sphinxcrossref{\DUrole{std,std-ref}{Formulation for IDL}}}})


\section{Description of the prediction process}
\label{\detokenize{sections/introduction:description-of-the-prediction-process}}
(see more at {\hyperref[\detokenize{sections/prediction:prediction}]{\sphinxcrossref{\DUrole{std,std-ref}{Predicting}}}})


\section{Setup}
\label{\detokenize{sections/introduction:setup}}
TODO

The package is compatible with Python version 3 or higher only.
The user is expected to have installed cvxpy before running the package.
Go to … for more information.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
Switch to a proper directory and then type:

\end{enumerate}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{git} \PYG{n}{clone} \PYG{o}{+} \PYG{n}{https}\PYG{p}{:}\PYG{o}{/}\PYG{o}{/}\PYG{n}{github}\PYG{o}{.}\PYG{n}{com}\PYG{o}{/}\PYG{o}{.}\PYG{o}{.}\PYG{o}{.}
\end{sphinxVerbatim}


\chapter{Formulation for IDL}
\label{\detokenize{sections/bi_convex_formulation:formulation-for-idl}}\label{\detokenize{sections/bi_convex_formulation:formulation}}\label{\detokenize{sections/bi_convex_formulation::doc}}
See {\hyperref[\detokenize{sections/citing:citing}]{\sphinxcrossref{\DUrole{std,std-ref}{Citing}}}} for in-depth explanation


\section{Problem formulation}
\label{\detokenize{sections/bi_convex_formulation:problem-formulation}}
Let us consider the input and output data matrices \(U = [u_1, \cdots, u_m] \in \mathbb{R}^{n \times m},Y = [y_1, \cdots, y_m] \in \mathbb{R}^{p \times m}\)
with \(m\) being the number of datapoints - the corresponding optimization regression problem (i.e. with
squared error loss) reads
\begin{equation}\label{equation:sections/bi_convex_formulation:eq_2}
\begin{split}\begin{align}
    \min_{\color{blue}{X}, \color{blue}{\Theta}} \quad &\mathcal{L}(Y,[\color{blue}{\Theta},\color{blue}{X}]) := \frac{1}{2m} \Vert \color{blue}{AX} + \color{blue}{B}U + \color{blue}{c}1_m^T - Y \Vert_F^2 \\
    \text{s.t.} \quad &\color{blue}{X}=(\color{blue}{DX} + \color{blue}{E}U + \color{blue}{f}1_m^T)_+ \\
                \quad &\Vert \color{blue}{D} \Vert_2 < 1,
\end{align}\end{split}
\end{equation}
where \(1_m\) is a column vector of size \(m\) consisting of ones. For clarity we have highlighted in \(\color{blue}{\text{blue}}\) the optimization variables.
The non-convexity of this problem arises from the nonlinear implicit constraint and
the matrix product terms \(AX\) and \(DX\). In practice we replace the constraint \(\Vert D \Vert_2 < 1\)
by the closed convex form \(\Vert D \Vert_2 \leq 1 - \epsilon\), where \(\epsilon > 0\) is small.


\section{Fenchel Divergence Lagrangian Relaxation}
\label{\detokenize{sections/bi_convex_formulation:fenchel-divergence-lagrangian-relaxation}}
Using Fenchel-Young inequality, it can be shown that the equation \(x = (Dx + Eu + f)_+\) is equivalent to
\begin{equation}\label{equation:sections/bi_convex_formulation:eq_3}
\begin{split}\begin{cases}
    \mathcal{F}(x,Ax + Bu + c) = 0 \\
    x \geq 0
\end{cases}\end{split}
\end{equation}
with the Fenchel Divergence \(\mathcal{F}\) defined by
\begin{equation*}
\begin{split}\mathcal{F}(x_1,x_2) := \frac{1}{2} x_1 \odot x_1 + \frac{1}{2} (x_2)_+ \odot (x_2)_+ - x_1 \odot x_2.\end{split}
\end{equation*}
We use the term divergence because by construction \(\mathcal{F}(x_1,x_2) \geq 0 \forall x_1,x_2 \in \mathbb{R}_+^h \times \mathbb{R}^h\).
Given \(X = [x_1, \cdots, x_m]\) and \(Z = [z_1, \cdots, z_m]\) we write
\begin{equation*}
\begin{split}\mathcal{F}(X,Z) := \frac{1}{m} \sum_{i=1}^m \mathcal{F}(x_i,z_i).\end{split}
\end{equation*}
A Lagrangian relaxation approach to solving \eqref{equation:sections/bi_convex_formulation:eq_2} problem using the implicit constraint formulation \eqref{equation:sections/bi_convex_formulation:eq_3} consists in
solving given a dual variable \(\lambda \in \mathcal{R}_+^h\)
\begin{equation}\label{equation:sections/bi_convex_formulation:eq_4}
\begin{split}\begin{align}
    \min_{\color{blue}{X} \geq 0, \color{blue}{\Theta}} \quad &\mathcal{L}(Y,[\color{blue}{\Theta},\color{blue}{X}]) + \lambda^T \mathcal{F}(\color{blue}{X},\color{blue}{DX} + \color{blue}{E}U + \color{blue}{f}1_m^T) \\
    \text{s.t.} \quad &\Vert \color{blue}{D} \Vert_2 < 1,
\end{align}\end{split}
\end{equation}
This problem is bi-smooth in \([\Theta,X]\), but it is not convex or bi-convex. Nevertheless we can make it bi-convex
with extra conditions on \(\Theta\) as shown in the next section.


\section{Linear matrix inequality parameter constraints for bi-convexity}
\label{\detokenize{sections/bi_convex_formulation:linear-matrix-inequality-parameter-constraints-for-bi-convexity}}
Let us define \(\Lambda = diag(\lambda) \in \mathbb{S}_+^h\)

Theorem 1. \sphinxstyleemphasis{Problem} \eqref{equation:sections/bi_convex_formulation:eq_4} \sphinxstyleemphasis{is bi-convex in} \([\Theta,X]\) \sphinxstyleemphasis{if we impose one of the two following feasible linear matrix inequalities (LMI)}
\begin{equation}\label{equation:sections/bi_convex_formulation:eq_5}
\begin{split}\Lambda - (\Lambda D + D^T \Lambda) \in \mathbb{S}_+^h \\\end{split}
\end{equation}\begin{equation}\label{equation:sections/bi_convex_formulation:eq_6}
\begin{split}\Lambda + A^TA - (\Lambda D + D^T \Lambda) \in \mathbb{S}_+^h \\\end{split}
\end{equation}
\sphinxstyleemphasis{Proof.} The loss term \(\mathcal{L}(Y,[\Theta,X])\) is already bi-convex in \((\Theta,X)\), but it is not the case for the Fenchel
Divergence term \(\lambda^T \mathcal{F}(X,DX + EU + f1_m^T)\), which is not convex in \(X\) in the general case. A sufficient
condition for this term to be convex in \(X\) given \(\Theta\) is for the following function
\begin{equation*}
\begin{split}x \rightarrow \lambda^T(\frac{1}{2} x \odot x - x \odot Dx) = \frac{1}{2}x^T(\Lambda - (\Lambda D + D^T \Lambda))x,\end{split}
\end{equation*}
to be convex. This term is convex in \(x\) if the LMI \eqref{equation:sections/bi_convex_formulation:eq_5} is satisfied. Now the second LMI similarly arises by
leveraging the fact that we can also use the term in the loss to make the objective convex in \(x\). Indeed the
objective function of \eqref{equation:sections/bi_convex_formulation:eq_2} is convex in \(x\) if
\begin{equation*}
\begin{split}x \rightarrow \frac{1}{2}x^TA^TAx + \frac{1}{2}x^T(\Lambda - (\Lambda D + D^T \Lambda))x,\end{split}
\end{equation*}
is convex, which corresponds to LMI \eqref{equation:sections/bi_convex_formulation:eq_6}. It might not be obvious that \eqref{equation:sections/bi_convex_formulation:eq_6} is actually an LMI, but using
Schur complement we can prove it is equivalent to
\begin{equation*}
\begin{split}- \begin{bmatrix}
        I_p & A \\
        A^T & \Lambda D + D^T \Lambda - \Lambda
    \end{bmatrix}
    \in \mathbb{S}_+^{p + h}.\end{split}
\end{equation*}
If D satisfies \eqref{equation:sections/bi_convex_formulation:eq_5} then it satisfies \eqref{equation:sections/bi_convex_formulation:eq_6}. We imediately have that \(D = \delta I_n\) with \(\delta \leq \frac{1}{2}\) satisfies \eqref{equation:sections/bi_convex_formulation:eq_5}
(and \(\Vert D \Vert_2 \leq 1 - \epsilon\)). Which proves that both LMIs are feasible.


\section{Bi-convex Formulation}
\label{\detokenize{sections/bi_convex_formulation:bi-convex-formulation}}
From this proof, the problem formulation reads
\begin{equation}\label{equation:sections/bi_convex_formulation:eq_7}
\begin{split}\begin{align}
    \min_{\color{blue}{X} \geq 0, \color{blue}{\Theta}} \quad &\mathcal{L}(Y,[\color{blue}{\Theta},\color{blue}{X}]) + \lambda^T \mathcal{F}(\color{blue}{X},\color{blue}{DX} + \color{blue}{E}U + \color{blue}{f}1_m^T) \\
    \text{s.t.} \quad &\Vert \color{blue}{D} \Vert_2 \leq 1 - \epsilon \\
                \quad &\Lambda + \color{blue}{A}^T\color{blue}{A} - (\Lambda \color{blue}{D} + \color{blue}{D}^T \Lambda) \in \mathbb{S}_+^h,
\end{align}\end{split}
\end{equation}
this problem is well-posed -feasible solutions exist- and bi-smooth.


\chapter{Learning Process}
\label{\detokenize{sections/learning:learning-process}}\label{\detokenize{sections/learning:learning}}\label{\detokenize{sections/learning::doc}}
** section 3.4 algo in the end **
\index{IDLModel (class in IDL)@\spxentry{IDLModel}\spxextra{class in IDL}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{sections/learning:IDL.IDLModel}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{IDL.}}\sphinxbfcode{\sphinxupquote{IDLModel}}}{\emph{hidden\_variables=1}, \emph{dual\_learning\_rate=0.1}, \emph{tol\_fenchtel=0.1}, \emph{inner\_tol=0.001}, \emph{starting\_lambda=None}, \emph{initialization\_theta=None}, \emph{random\_state=0}, \emph{early\_stopping=True}, \emph{verbosity=True}}{}
Implementation of the Scikit-Learn API for Implicit Deep Learning
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{hidden\_variables}} \textendash{} int
number of hidden variables of the vector X (see

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{dual\_learning\_rate}} \textendash{} float
Positive float, Dual learning rate (IDL’s “alpha”)

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tol\_fenchel}} \textendash{} float
Positive float, Fenchel tolerance threshold for dual’s update (IDL’s “alpha”)

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{inner\_tol}} \textendash{} float
Positive float, tolerance threshold for early stopping in the gradient descents with respect to theta

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbosity}} \textendash{} bool
Verbosity of the training process.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{random\_state}} \textendash{} int
Random number seed for initialization.

\end{itemize}

\end{description}\end{quote}
\begin{description}
\item[{Full documentation of parameters can}] \leavevmode
be found here: \sphinxurl{https://github.com/GuillaumeGoujard/IDLEstimator/blob/master/docs/source/sections/introduction.rst}.

\end{description}
\index{fit() (IDL.IDLModel method)@\spxentry{fit()}\spxextra{IDL.IDLModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{sections/learning:IDL.IDLModel.fit}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{fit}}}{\emph{X}, \emph{y}, \emph{rounds\_number=100}, \emph{verbose=True}, \emph{type\_of\_training='two\_loops'}}{}
Fit IDL Model
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{X}} \textendash{} array\_like
Feature matrix

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{y}} \textendash{} array\_like
Labels

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{rounds\_number}} \textendash{} int
Maximum rounds number in the outer loop

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} \textendash{} bool

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{type\_of\_training}} \textendash{} 
string
Two types of training :
\begin{quote}
\begin{itemize}
\item {} 
”two\_loops” : RECOMMENDED, we optimize theta and X variables and then we do one step of dual ascent.

\item {} 
”one\_loop” : one iteration is going to successively operate one step of gradient descent and one step

\end{itemize}

of dual ascent
\end{quote}


\end{itemize}

\item[{Returns}] \leavevmode
self : object
Returns self.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Gradient Descents}
\label{\detokenize{sections/gradient_descents:gradient-descents}}\label{\detokenize{sections/gradient_descents:id1}}\label{\detokenize{sections/gradient_descents::doc}}

\section{Block coordinate descent and first order methods}
\label{\detokenize{sections/gradient_descents:block-coordinate-descent-and-first-order-methods}}
As problem \eqref{equation:sections/bi_convex_formulation:eq_7} is bi-convex, a natural strategy is the use of block coordinate descent (BCD): alternating
optimization between \(\Theta\). BCD corresponds to the following algorithm,

\sphinxstylestrong{for} \(k = 1, 2, \cdots\) \sphinxstylestrong{do}
\begin{equation*}
\begin{split}\begin{align}
    \Theta^k \in \text{argmin}_{\Theta} &\frac{1}{2m} \Vert AX^{k-1} + BU + c1_m^T - Y \Vert_F^2 + \lambda^T \mathcal{F}(X^{k-1},DX^{k-1} + EU + f1_m^T) \\
        &\quad \Lambda + A^TA - (\Lambda D + D^T \Lambda) \in \mathbb{S}_+^h, \\
        &\quad \Vert D \Vert_2 \leq 1 - \epsilon \\
    X^k \in \text{argmin}_{X \geq 0} &\frac{1}{2m}\Vert A^kX + B^kU + c^k1_m^T - Y \Vert_F^2 + \lambda^T \mathcal{F}(X,D^kX + E^kU + f^k1_m^T)
\end{align}\end{split}
\end{equation*}
\sphinxstylestrong{end}

In practice such updates might be to heavy computationally as the number of datapoints \(m\) increase, or
as the model size increases (i.e. \(h\), \(n\) or \(p\)). Instead we propose to do block coordinate projected gradient
updates. This method is also considered to be better at avoiding local minima. Let us denote
\begin{equation*}
\begin{split}\mathcal{G}(\Theta,X) := \mathcal{L}(Y,[\Theta,X]) + \lambda^T \mathcal{F}(X,DX + EU + f1_m^T)\end{split}
\end{equation*}
In the remainder of this section we derive the gradients \(\nabla_{\Theta} \mathcal{G}(\Theta,X), \nabla_X \mathcal{G}(\Theta,X)\) and corresponding ‘optimal’
step-sizes using the Lipschitz coefficients of the gradients- which is the advantage of having a bi-smooth
optimization problem. Note that the objective \(\mathcal{G}\), given \(X\) is separable in \(\Theta_1 := (A,B,c)\) and \(\Theta_2 := (D,E,f)\).
Using scalar by matrix calculus
\begin{equation*}
\begin{split}\begin{cases}
        \nabla_A \mathcal{G}(\Theta,X) = \Omega(A,B,c)X^T \in \mathbb{R}^{p \times h} \\
        \nabla_B \mathcal{G}(\Theta,X) = \Omega(A,B,c)U^T \in \mathbb{R}^{p \times n} \\
\nabla_c \mathcal{G}(\Theta,X) = \Omega(A,B,c)1_m \in \mathbb{R}^p
\end{cases},\end{split}
\end{equation*}
with \(\Omega(A,B,c) := \frac{1}{m}(AX + BU + c1_m^T - Y) \in \mathbb{R}^{p \times m}\). Hence we can show that a Lipschitz constant for the
gradient is given by
\begin{equation*}
\begin{split}L_{\Theta_1}(X) := \frac{1}{m} \max(m,\Vert X \Vert_2^2,\Vert U \Vert_2^2,\Vert XU^T \Vert_2),\end{split}
\end{equation*}
and the ‘optimal’ step-size for gradient descent is then simply given by
\begin{equation*}
\begin{split}\alpha_{\Theta_1}(X) := \frac{1}{L_{\Theta}(X)}.\end{split}
\end{equation*}
Regarding the gradient with respect to \(\Theta_2\), we have
\begin{equation*}
\begin{split}\begin{cases}
        \nabla_D \mathcal{G}(\Theta,X) = \Omega(D,E,f,\Lambda)X^T \in \mathbb{R}^{h \times h} \\
        \nabla_E \mathcal{G}(\Theta,X) = \Omega(D,E,f,\Lambda)U^T \in \mathbb{R}^{h \times n} \\
\nabla_f \mathcal{G}(\Theta,X) = \Omega(D,E,f,\Lambda)1_m \in \mathbb{R}^h
\end{cases},\end{split}
\end{equation*}
with \(\Omega(D,E,f,\Lambda) := \frac{\Lambda}{m}\bigg((DX + EU + f1_m^T)_+ - X \bigg) \in \mathbb{R}^{h \times m}\), we can show that a Lipschitz constant for the
gradient is
\begin{equation*}
\begin{split}L_{\Theta_2}(X) := \frac{\lambda_{\text{max}}}{m} \max(m,\Vert X \Vert_2^2,\Vert U \Vert_2^2,\Vert X \Vert_2 \Vert U \Vert_2),\end{split}
\end{equation*}
where \(\lambda_{\text{max}} = \text{max}_{j \in \{1,\cdots,h\}} \lambda_j\). We can then similarly define an ‘optimal’ step-size \(\alpha \Theta_2\).
We have that
\begin{equation*}
\begin{split}\nabla_X \mathcal{G}(\Theta,X) = \frac{1}{m} \bigg\{ A^T(AX + BU + c1_m^T) + (\Lambda - \Lambda D - D^T \Lambda)X + D^T \Lambda (DX + EU + f1_m^T)_+ - \Lambda(EU+f1_m^T) \bigg\}.\end{split}
\end{equation*}
A Lipschitz constant for this gradient is
\begin{equation*}
\begin{split}L_X(\Theta) = \frac{1}{m}(\Vert A^TA + \Lambda - \Lambda D + D^T\Lambda \Vert_2 + \lambda_{\text{max}} \Vert D \Vert_2^2).\end{split}
\end{equation*}
We can then take the step-size \(\alpha_X(\Theta) = \frac{1}{L_X(\Theta)}\). We propose the following block coordinate projected
gradient scheme (BC-gradient) to  nd a candidate solution to :eq:{\color{red}\bfseries{}{}`}eq\_7. We denote compactly the convex set
\begin{equation*}
\begin{split}\mathcal{S}_{\Theta} := \{\Theta \vert \Lambda + A^TA - (\Lambda D + D^T \Lambda) \in \mathbb{s}_+^h, \Vert D \Vert_2 \leq 1 - \epsilon \}\end{split}
\end{equation*}
and \(\mathcal{P}_{\mathcal{S}_{\Theta}}\) the corresponding convex projection

\sphinxstylestrong{for} \(k = 1, 2, \cdots\) \sphinxstylestrong{do}
\begin{equation*}
\begin{split}\begin{align}
    \Theta^k &= \mathcal{P}_{\mathcal{S}_{\Theta}}\bigg(\Theta^k - \alpha_{\Theta}(X^{k-1}) \nabla_{\Theta} \mathcal{G}(\Theta^{k-1},X^{k-1}) \bigg) \\
    X^k &= \bigg(X^{k-1} - \alpha_X(\Theta^k) \nabla_X \mathcal{G}(\Theta^k,X^{k-1}) \bigg)
\end{align}\end{split}
\end{equation*}
\sphinxstylestrong{end}


\section{Bi-Convexity of the Loss function}
\label{\detokenize{sections/gradient_descents:bi-convexity-of-the-loss-function}}
TODO


\section{Gradient Descents}
\label{\detokenize{sections/gradient_descents:id4}}
TODO


\section{Code for calculating Gradient Descent}
\label{\detokenize{sections/gradient_descents:code-for-calculating-gradient-descent}}\phantomsection\label{\detokenize{sections/gradient_descents:module-utilities.GradientDescents}}\index{utilities.GradientDescents (module)@\spxentry{utilities.GradientDescents}\spxextra{module}}\index{gradient\_descent\_theta() (in module utilities.GradientDescents)@\spxentry{gradient\_descent\_theta()}\spxextra{in module utilities.GradientDescents}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{sections/gradient_descents:utilities.GradientDescents.gradient_descent_theta}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{utilities.GradientDescents.}}\sphinxbfcode{\sphinxupquote{gradient\_descent\_theta}}}{\emph{theta}, \emph{X}, \emph{U}, \emph{Y}}{}
Returns the gradient of theta
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{theta}} \textendash{} a dictionary

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{X}} \textendash{} hidden variables

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{U}} \textendash{} input data

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{Y}} \textendash{} output data

\end{itemize}

\item[{Returns}] \leavevmode
grad\_theta: dictionary containing gradients of elemnts in theta

\end{description}\end{quote}

\end{fulllineitems}



\chapter{Dual Ascents}
\label{\detokenize{sections/dual_ascents:dual-ascents}}\label{\detokenize{sections/dual_ascents:id1}}\label{\detokenize{sections/dual_ascents::doc}}

\section{Dual methods}
\label{\detokenize{sections/dual_ascents:dual-methods}}
We propose the following schemes to  find an appropriate dual variable \(\lambda\). Let \(\epsilon > 0\) be a precision parameter
for the implicit constraint, i.e. such that we would have
\begin{equation*}
\begin{split}\mathcal{F}(X,DX + EU + f1_m^T) \leq \epsilon\end{split}
\end{equation*}
We start with \(\lambda = 0\) and we solve the two following separate problems
\begin{equation*}
\begin{split}\min_{\color{blue}{X} > 0, \color{blue}{A}, \color{blue}{B}, \color{blue}{c}} \frac{1}{m} \Vert \color{blue}{AX} + \color{blue}{B}U + \color{blue}{c}1_m^T - Y \Vert_F^2\end{split}
\end{equation*}
and then
\begin{equation*}
\begin{split}\min_{\color{blue}{D}, \color{blue}{E}, \color{blue}{f}} 1_h^T\mathcal{F}(\color{blue}{X},\color{blue}{DX} + \color{blue}{E}U + \color{blue}{f}1_m^T).\end{split}
\end{equation*}
If \(\mathcal{F}^* := \mathcal{F}(X,DX + EU + f1_m^T) < \epsilon I_h\) then we stop there. Otherwise, we do one of the two following ‘dual
updates’


\section{Dual ascent conditional on Fenchel Divergence}
\label{\detokenize{sections/dual_ascents:dual-ascent-conditional-on-fenchel-divergence}}\begin{equation}\label{equation:sections/dual_ascents:eq_8}
\begin{split}\lambda \leftarrow \lambda + \alpha \mathcal{F}^* \odot 1\{\mathcal{F}^* \geq \epsilon I_h\},\end{split}
\end{equation}
where \(\alpha > 0\) is a step-size. Note that here we only update the components of \(\lambda\) for which the corresponding
Fenchel divergence is more than \(\epsilon\). We then proceed to solve \eqref{equation:sections/bi_convex_formulation:eq_7} using previously discussed methods and
iterate. Alternatively, if the BC-gradient method is used, we can do a dual update after each BC-gradient
update.


\section{Dual variable update conditional on loss}
\label{\detokenize{sections/dual_ascents:dual-variable-update-conditional-on-loss}}
We start with \(\lambda = \epsilon I_h\). Given \((\Theta,X)\), we define the unique \(\bar{X}\) such that the implicit constraint
is enforced given \(\Theta\)
\begin{equation*}
\begin{split}\bar{X} = (DX + EU + f1_m^T)_+.\end{split}
\end{equation*}
We then define \(\Delta X := X - \bar{X}\). We can compute in close form the error on the loss due to the implicit
constraint violation
\begin{equation*}
\begin{split}\begin{align}
    \Delta \mathcal{L} :&= \mathcal{L}(Y,[\Theta,\bar{X}]) - \mathcal{L}(Y,[\Theta,X]) \\
    &= \frac{1}{2m} \bigg(\Vert A \Delta X \Vert_F^2 + Tr(\Omega,A \Delta X) \bigg)
\end{align}\end{split}
\end{equation*}
with \(\Omega := BU + c1_m^T\). We can write this error as a sum of contributions with respect to each hidden variable
components \(j \in \{1,\cdots,h\}\)
\begin{equation*}
\begin{split}\Delta \mathcal{L} = \sum_{j=1}^h \bigg\{ \Delta \mathcal{L}_j := \frac{1}{m} A_j^T \bigg( \frac{1}{2} A \Delta X + \Omega \bigg) \Delta X_j^T \bigg\},\end{split}
\end{equation*}
where \(A_j \in \mathbb{R}^h\) is the \(j^{th}\) column of \(A\) and \(\Delta X_j \in \mathbb{R}^{1 \times m}\) is the \(j^{th}\)
row of \(\Delta X\). The objective of this dual update is to achieve an error on the loss that is smaller than a fraction \(\eta \in (0,1)\) of the loss
\begin{equation*}
\begin{split}\frac{\Delta \mathcal{L}}{\mathcal{L}(Y,[\Theta,\bar{X}])} \leq \eta.\end{split}
\end{equation*}
In order to update each component of the dual variable, we propose the following update. Given \(j \in \{1,\cdots,h\}\) if
\begin{equation*}
\begin{split}\frac{(\Delta \mathcal{L}_j)_+}{\mathcal{L}(Y,[\Theta,\bar{X}])} \geq \frac{\eta}{h},\end{split}
\end{equation*}
then we do the update
\begin{equation*}
\begin{split}\lambda_j \rightarrow \beta \lambda_j,\end{split}
\end{equation*}
with \(\beta > 1\) a hyperparameter.


\section{Code for calculating Dual Ascents}
\label{\detokenize{sections/dual_ascents:code-for-calculating-dual-ascents}}\phantomsection\label{\detokenize{sections/dual_ascents:module-utilities.DualAscents}}\index{utilities.DualAscents (module)@\spxentry{utilities.DualAscents}\spxextra{module}}

\chapter{Predicting}
\label{\detokenize{sections/prediction:predicting}}\label{\detokenize{sections/prediction:prediction}}\label{\detokenize{sections/prediction::doc}}
** section 2 Picard iterations **
\index{IDLModel (class in IDL)@\spxentry{IDLModel}\spxextra{class in IDL}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{sections/prediction:IDL.IDLModel}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class }}\sphinxcode{\sphinxupquote{IDL.}}\sphinxbfcode{\sphinxupquote{IDLModel}}}{\emph{hidden\_variables=1}, \emph{dual\_learning\_rate=0.1}, \emph{tol\_fenchtel=0.1}, \emph{inner\_tol=0.001}, \emph{starting\_lambda=None}, \emph{initialization\_theta=None}, \emph{random\_state=0}, \emph{early\_stopping=True}, \emph{verbosity=True}}{}
Implementation of the Scikit-Learn API for Implicit Deep Learning
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode\begin{itemize}
\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{hidden\_variables}} \textendash{} int
number of hidden variables of the vector X (see

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{dual\_learning\_rate}} \textendash{} float
Positive float, Dual learning rate (IDL’s “alpha”)

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{tol\_fenchel}} \textendash{} float
Positive float, Fenchel tolerance threshold for dual’s update (IDL’s “alpha”)

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{inner\_tol}} \textendash{} float
Positive float, tolerance threshold for early stopping in the gradient descents with respect to theta

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{verbosity}} \textendash{} bool
Verbosity of the training process.

\item {} 
\sphinxstyleliteralstrong{\sphinxupquote{random\_state}} \textendash{} int
Random number seed for initialization.

\end{itemize}

\end{description}\end{quote}
\begin{description}
\item[{Full documentation of parameters can}] \leavevmode
be found here: \sphinxurl{https://github.com/GuillaumeGoujard/IDLEstimator/blob/master/docs/source/sections/introduction.rst}.

\end{description}
\index{predict() (IDL.IDLModel method)@\spxentry{predict()}\spxextra{IDL.IDLModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{sections/prediction:IDL.IDLModel.predict}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{predict}}}{\emph{X}, \emph{k\_iterations=10000}}{}
Predicting function.
:param X: array-like
\begin{quote}

The input sample.
\end{quote}
\begin{quote}\begin{description}
\item[{Parameters}] \leavevmode
\sphinxstyleliteralstrong{\sphinxupquote{k\_iterations}} \textendash{} int
Maximum number of Picard iterations

\item[{Returns}] \leavevmode
y: array-like
Returns a prediction array.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\chapter{Examples}
\label{\detokenize{sections/classification_operational_example:examples}}\label{\detokenize{sections/classification_operational_example::doc}}

\section{\sphinxstylestrong{Classification : MNIST}}
\label{\detokenize{sections/classification_operational_example:classification-mnist}}

\section{\sphinxstylestrong{Regression : Boston Housing}}
\label{\detokenize{sections/classification_operational_example:regression-boston-housing}}

\chapter{Citing}
\label{\detokenize{sections/citing:citing}}\label{\detokenize{sections/citing:id1}}\label{\detokenize{sections/citing::doc}}\begin{itemize}
\item {} 
“Implicit Deep Learning” Laurent El Ghaoui, Fangda Gu, Bertrand Travacca, Armin Askari, arXiv:1908.06315, 2019.

\item {} 
“Bi-convex Implicit Deep Learning” Bertrand Travacca, October 2019

\end{itemize}


\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{u}
\item\relax\sphinxstyleindexentry{utilities.DualAscents}\sphinxstyleindexpageref{sections/dual_ascents:\detokenize{module-utilities.DualAscents}}
\item\relax\sphinxstyleindexentry{utilities.GradientDescents}\sphinxstyleindexpageref{sections/gradient_descents:\detokenize{module-utilities.GradientDescents}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}